# Solving CartPole Gym environment using Q learning

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

To run it you will need the following dependencies:

```
import numpy as np
import gym
import matplotlib.pyplot as plt
import math
```

### Installing

To clone the repository execute the following command:

```
git clone git@github.com:Alvaro2112/Solving-CartPole-Gym-environment-using-Q-learning.git
```

## Running the tests

To train the model you can simply run:

```
python CartPole_Q.py 
```

If you wish, you can play around with the Hyperparameters to try to better the convergence time.

### Results


![Rewards vs Episodes](/rewards.jpg)

## Built With

* [OpenAI Gym](https://gym.openai.com/) - Environmnet used to train the Agent

## Authors

* **Alvaro Caud√©ran**

## Acknowledgments

* Part of this code was taken from https://github.com/sanjitjain2/q-learning-for-cartpole/blob/master/qlearning.py


